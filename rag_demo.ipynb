{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# RAG Application Demo\n",
        "\n",
        "This notebook demonstrates how to use the RAG (Retrieval-Augmented Generation) application for chatting with your documents using OpenAI-compatible APIs.\n",
        "\n",
        "## Features\n",
        "\n",
        "- üìÑ **Document Processing**: Support for PDF, DOCX, TXT, MD, and more\n",
        "- üß† **Smart Chunking**: Intelligent text splitting for optimal retrieval\n",
        "- üîç **Vector Search**: FAISS-powered similarity search\n",
        "- üí¨ **Chat Interface**: Interactive conversation with context\n",
        "- üîß **OpenAI Compatible**: Works with OpenAI and compatible APIs\n",
        "\n",
        "## Setup\n",
        "\n",
        "Make sure you have your OpenAI API key ready!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import RAG components\n",
        "from rag_app import EmbeddingService, VectorStore, DocumentProcessor, RAGEngine\n",
        "from rag_app.vector_store import Document\n",
        "\n",
        "# For demo purposes\n",
        "import json\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "print(\"‚úÖ Imports successful!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Configuration\n",
        "\n",
        "Set up your API credentials and model preferences:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration Options\n",
        "# Choose your API provider by uncommenting the appropriate section below\n",
        "\n",
        "# === OPTION 1: OpenAI (Default) ===\n",
        "API_KEY = \"your-openai-api-key-here\"\n",
        "BASE_URL = None\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "CHAT_MODEL = \"gpt-4o-mini\"\n",
        "ENDPOINT_TYPE = \"OpenAI\"\n",
        "\n",
        "# === OPTION 2: Nutanix Enterprise AI ===\n",
        "# API_KEY = \"your-nutanix-api-key\"\n",
        "# BASE_URL = \"https://your-nutanix-endpoint/v1\"\n",
        "# EMBEDDING_MODEL = \"your-embedding-model-name\"  # e.g., \"text-embedding-3-small\"\n",
        "# CHAT_MODEL = \"your-chat-model-name\"            # e.g., \"llama2-7b-chat\"\n",
        "# ENDPOINT_TYPE = \"Nutanix Enterprise AI\"\n",
        "# EMBEDDING_DIMENSION = 1536  # Set this to your model's embedding dimension\n",
        "\n",
        "# === OPTION 3: Azure OpenAI ===\n",
        "# API_KEY = \"your-azure-api-key\"\n",
        "# BASE_URL = \"https://your-resource.openai.azure.com/\"\n",
        "# EMBEDDING_MODEL = \"your-embedding-deployment-name\"\n",
        "# CHAT_MODEL = \"your-chat-deployment-name\"\n",
        "# ENDPOINT_TYPE = \"Azure OpenAI\"\n",
        "# API_VERSION = \"2023-05-15\"\n",
        "\n",
        "# === OPTION 4: Custom Endpoint ===\n",
        "# API_KEY = \"your-custom-api-key\"\n",
        "# BASE_URL = \"https://your-custom-endpoint/v1\"\n",
        "# EMBEDDING_MODEL = \"your-embedding-model\"\n",
        "# CHAT_MODEL = \"your-chat-model\"\n",
        "# ENDPOINT_TYPE = \"Custom\"\n",
        "\n",
        "# RAG configurations (same for all endpoints)\n",
        "CHUNK_SIZE = 1000\n",
        "CHUNK_OVERLAP = 200\n",
        "MAX_RETRIEVED_DOCS = 5\n",
        "\n",
        "print(\"‚úÖ Configuration set!\")\n",
        "print(f\"üåê Endpoint Type: {ENDPOINT_TYPE}\")\n",
        "print(f\"üìã Embedding Model: {EMBEDDING_MODEL}\")\n",
        "print(f\"ü§ñ Chat Model: {CHAT_MODEL}\")\n",
        "print(f\"üîó Base URL: {BASE_URL or 'Default (OpenAI)'}\")\n",
        "print(f\"üìè Chunk Size: {CHUNK_SIZE}\")\n",
        "print(f\"üîÑ Chunk Overlap: {CHUNK_OVERLAP}\")\n",
        "\n",
        "if BASE_URL:\n",
        "    print(\"‚ö†Ô∏è  Make sure your custom endpoint is OpenAI-compatible!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Quick Start Example\n",
        "\n",
        "Let's create a simple RAG system and test it:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize RAG components\n",
        "print(\"üöÄ Initializing RAG System...\")\n",
        "\n",
        "# Note: Make sure to set your API_KEY above!\n",
        "# For demo purposes, we'll check if API_KEY is set\n",
        "if API_KEY == \"your-openai-api-key-here\":\n",
        "    print(\"‚ö†Ô∏è  Please set your OpenAI API key in the cell above!\")\n",
        "    print(\"   Set API_KEY = 'sk-...' with your actual key\")\n",
        "else:\n",
        "    try:\n",
        "        # Initialize embedding service\n",
        "        embedding_service = EmbeddingService(\n",
        "            api_key=API_KEY,\n",
        "            base_url=BASE_URL,\n",
        "            model_name=EMBEDDING_MODEL\n",
        "        )\n",
        "        \n",
        "        # Get embedding dimension\n",
        "        embedding_dim = embedding_service.get_embedding_dimension()\n",
        "        print(f\"üìê Embedding dimension: {embedding_dim}\")\n",
        "        \n",
        "        # Initialize vector store\n",
        "        vector_store = VectorStore(dimension=embedding_dim, index_type=\"flat\")\n",
        "        \n",
        "        # Initialize document processor  \n",
        "        document_processor = DocumentProcessor(\n",
        "            chunk_size=CHUNK_SIZE,\n",
        "            chunk_overlap=CHUNK_OVERLAP,\n",
        "            chunking_strategy=\"recursive\"\n",
        "        )\n",
        "        \n",
        "        # Initialize RAG engine\n",
        "        rag_engine = RAGEngine(\n",
        "            embedding_service=embedding_service,\n",
        "            vector_store=vector_store,\n",
        "            document_processor=document_processor,\n",
        "            api_key=API_KEY,\n",
        "            base_url=BASE_URL,\n",
        "            model_name=CHAT_MODEL,\n",
        "            temperature=0.7,\n",
        "            max_retrieved_docs=MAX_RETRIEVED_DOCS\n",
        "        )\n",
        "        \n",
        "        print(\"‚úÖ RAG system initialized successfully!\")\n",
        "        \n",
        "        # Add some sample text\n",
        "        sample_text = \"\"\"\n",
        "        Artificial Intelligence (AI) is a branch of computer science that aims to create \n",
        "        intelligent machines that can think and act like humans. AI systems can learn, \n",
        "        reason, and make decisions. Machine Learning is a subset of AI that enables \n",
        "        computers to learn and improve from experience without being explicitly programmed.\n",
        "        \n",
        "        Natural Language Processing (NLP) is another important area of AI that focuses on \n",
        "        enabling computers to understand, interpret, and generate human language. NLP is \n",
        "        used in applications like chatbots, language translation, and text analysis.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Add the sample text to the knowledge base\n",
        "        doc_ids = rag_engine.add_text(\n",
        "            sample_text, \n",
        "            source=\"AI_overview\", \n",
        "            metadata={\"topic\": \"artificial_intelligence\", \"type\": \"educational\"}\n",
        "        )\n",
        "        \n",
        "        print(f\"üìö Added sample document with {len(doc_ids)} chunks\")\n",
        "        \n",
        "        # Test the system with a question\n",
        "        print(\"\\nüí¨ Testing the RAG system:\")\n",
        "        question = \"What is the difference between AI and Machine Learning?\"\n",
        "        print(f\"Question: {question}\")\n",
        "        \n",
        "        response = rag_engine.ask(question)\n",
        "        print(f\"Answer: {response}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        print(\"Make sure you have a valid OpenAI API key!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Custom Endpoint Examples\n",
        "\n",
        "Here are examples of how to configure the RAG system for different API providers:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example configurations for different endpoints\n",
        "print(\"üîß Configuration Examples:\\n\")\n",
        "\n",
        "# Example 1: Nutanix Enterprise AI\n",
        "print(\"1Ô∏è‚É£ Nutanix Enterprise AI Configuration:\")\n",
        "print(\"\"\"\n",
        "# For Nutanix Enterprise AI\n",
        "rag_engine = RAGEngine.create_for_nutanix(\n",
        "    api_key=\"your-nutanix-api-key\",\n",
        "    base_url=\"https://your-nutanix-cluster/v1\",\n",
        "    embedding_model=\"text-embedding-3-small\",  # Your embedding model\n",
        "    chat_model=\"llama2-7b-chat\",               # Your chat model  \n",
        "    embedding_dimension=1536,                  # Model's embedding dimension\n",
        "    chunk_size=1000,\n",
        "    temperature=0.7\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "# Example 2: Azure OpenAI\n",
        "print(\"2Ô∏è‚É£ Azure OpenAI Configuration:\")\n",
        "print(\"\"\"\n",
        "# For Azure OpenAI\n",
        "embedding_service = EmbeddingService.create_for_azure(\n",
        "    api_key=\"your-azure-key\",\n",
        "    base_url=\"https://your-resource.openai.azure.com/\",\n",
        "    model_name=\"your-embedding-deployment\",\n",
        "    api_version=\"2023-05-15\"\n",
        ")\n",
        "\n",
        "rag_engine = RAGEngine(\n",
        "    embedding_service=embedding_service,\n",
        "    vector_store=vector_store,\n",
        "    document_processor=document_processor,\n",
        "    api_key=\"your-azure-key\",\n",
        "    base_url=\"https://your-resource.openai.azure.com/\",\n",
        "    model_name=\"your-chat-deployment\"\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "# Example 3: Local API (e.g., Ollama)\n",
        "print(\"3Ô∏è‚É£ Local API Configuration:\")\n",
        "print(\"\"\"\n",
        "# For local APIs like Ollama\n",
        "embedding_service = EmbeddingService(\n",
        "    api_key=\"not-needed\",  # Local APIs often don't need keys\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    model_name=\"nomic-embed-text\"\n",
        ")\n",
        "\n",
        "rag_engine = RAGEngine(\n",
        "    embedding_service=embedding_service,\n",
        "    vector_store=vector_store,\n",
        "    document_processor=document_processor,\n",
        "    api_key=\"not-needed\",\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    model_name=\"llama2:7b\"\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "print(\"‚ú® Choose the configuration that matches your setup!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
